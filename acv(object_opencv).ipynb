{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "noble-turtle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twithout helmet: 99.65%, object at location (X1, Y1, X2, Y2): 0.50, 0.58, 0.10, 0.30\n",
      "\twithout helmet: 98.56%, object at location (X1, Y1, X2, Y2): 0.78, 0.86, 0.15, 0.35\n",
      "\twithout helmet: 98.27%, object at location (X1, Y1, X2, Y2): 0.71, 0.82, 0.14, 0.70\n",
      "\twithout helmet: 97.88%, object at location (X1, Y1, X2, Y2): 0.20, 0.27, 0.13, 0.35\n",
      "\twithout helmet: 96.40%, object at location (X1, Y1, X2, Y2): 0.05, 0.15, 0.20, 0.33\n",
      "\twithout helmet: 94.43%, object at location (X1, Y1, X2, Y2): 0.00, 0.02, 0.16, 0.28\n",
      "\twithout helmet: 91.30%, object at location (X1, Y1, X2, Y2): 0.51, 0.65, 0.12, 0.53\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# Replace with valid values\n",
    "ENDPOINT = \"https://tfb112.cognitiveservices.azure.com/\"\n",
    "training_key = \"704e8a45398c4ef486791d0e4d7de38c\"\n",
    "prediction_key = \"dc2ae4575a3043dc8cb64ccd317966ed\"\n",
    "prediction_resource_id = \"31080632-bc04-448b-9ab9-69ec218fa8d3\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)\n",
    "\n",
    "publish_iteration_name = \"hat\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
    "\n",
    "#使用絕對路徑\n",
    "base_image_location = \"C:\\\\Users\\\\Tibame\\\\Desktop\\\\AzureStarFace\\\\test2\\\\\"\n",
    "\n",
    "# <snippet_test>\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)\n",
    "\n",
    "\n",
    "#用本機的照片進行測試\n",
    "with open(base_image_location + \"test3.jpg\", mode=\"rb\") as test_data:\n",
    "    results = predictor.detect_image('31080632-bc04-448b-9ab9-69ec218fa8d3', publish_iteration_name, test_data)\n",
    "    \n",
    "    \n",
    "# # Display the results.    \n",
    "# for prediction in results.predictions:\n",
    "#     print(\"\\t\" + prediction.tag_name + \": {0:.2f}% bbox.left = {1:.2f}, bbox.top = {2:.2f}, bbox.width = {3:.2f}, bbox.height = {4:.2f}\".format(prediction.probability , prediction.bounding_box.left, prediction.bounding_box.top, prediction.bounding_box.width, prediction.bounding_box.height))\n",
    "    \n",
    "\n",
    "img_path ='C:\\\\Users\\\\Tibame\\\\Desktop\\\\AzureStarFace\\\\test2\\\\test3.jpg'\n",
    "   \n",
    "# Reading an image in default mode \n",
    "image = cv2.imread(img_path) \n",
    "\n",
    "sp = image.shape[:]\n",
    "imageheigh = sp[0]\n",
    "imageWidth = sp[1]\n",
    "\n",
    "# Window name in which image is displayed \n",
    "window_name = 'Image'\n",
    "  \n",
    "# Blue color in BGR \n",
    "color = (255, 0, 0) \n",
    "  \n",
    "# Line thickness of 2 px \n",
    "thickness = 2\n",
    "\n",
    "# Display the results in op\n",
    "for o in results.predictions:\n",
    "    if o.probability >= 0.9:\n",
    "        print(\"\\t\" + prediction.tag_name + \": {0:.2f}%, object at location (X1, Y1, X2, Y2): {1:.2f}, {2:.2f}, {3:.2f}, {4:.2f}\".format(o.probability * 100, \\\n",
    "        o.bounding_box.left, o.bounding_box.left + o.bounding_box.width, o.bounding_box.top, o.bounding_box.top + o.bounding_box.height))\n",
    "        X1 = int(o.bounding_box.left* imageWidth)\n",
    "        Y1 = int(o.bounding_box.top * imageheigh)\n",
    "        X2 = int(o.bounding_box.width* imageWidth + X1)\n",
    "        Y2 = int(o.bounding_box.height * imageheigh + Y1)\n",
    "         \n",
    "        cv2.rectangle(image, (X1,Y1), (X2,Y2), color , thickness)    \n",
    "        cv2.putText(image, str(prediction.tag_name) ,(X1-20, Y1-20), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.7, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "print('====================')\n",
    "\n",
    "\n",
    "# Displaying the image  \n",
    "cv2.imshow(window_name, image)\n",
    "cv2.imwrite('output.jpg', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
